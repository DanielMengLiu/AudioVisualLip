#============================= DATA ============================================================================
# change path to your train manifest and dirs
train_manifest: data/manifest/vvoxceleb2_dev_manifest.csv
train_audiodir: /local01/liumeng/voxceleb2/audio/dev/aac/
train_videodir: /datasets3/voxceleb2/face/
# change path to your train trial and dirs
test_trial: data/trial/vox1_O.txt              # vox1_O.txt | vox1_E.txt | vox1_H.txt | voxsrc2022_dev.txt
test_audiodir: /local01/liumeng/voxceleb1/audio/
# change path to your splited musan and rir paths
musan_path: /datasets1/musan_split/            # split musan will load faster
rir_path: /datasets1/RIRS_NOISES/simulated_rirs/
#============================= STAGE =============================================================================
train:
  gpus: [0,1,2]                                # example: [0] | [3,5] | [] (for cpu)
  audiomodel: MFA-Conformer                    # choose a model from [MODEL ZOO]
  visualmodel: ResNet18                        # choose a model from [MODEL ZOO]
  audioresume: None                            # None (from scratch) | exp/${train.model}/net_10.pth (continuous training)
  visualresume: None                           # None (from scratch) | exp/${train.model}/net_10.pth (continuous training)
  seconds: [3.0, 3.0]                          # example: [2.0,3.0] variable chunk sampler | [2.0,2.0] fixed 2s
  epochs: 60                                   # num of epochs
  batchsize: 88                                # batchsize
  optimizer: adam                              # sgd | adam | nadam
  lr_scheduler: steplr                         # steplr | cycliclr 
  warmup_steps: 2000                           # example: 2000 | 0 (not warmup) 
  flood: None                                  # None | Yes
  scale: 30                                    # 30 | 32
  margins: [0.0, 0.2]                          # example: [0.0,0.2] gradually increase | [0.2,0.2] fixed margin 0.2
  augmentation: {'noiseaug': 0.6,
                  'specaug': 0.3,
             'speedperturb': [1.0]}
  validate_steps: 4                             
  validate_num_workers: 1                      # number of workers doing validation
  savemodel_steps: 1                           # save and test performance later
  wandb: online                                # off | online | offline

finetune:
  gpus: [1,2]                                  # example: [0] | [3,5] | [] (for cpu)
  audiomodel: MFA-Conformer                    # choose a model from [MODEL ZOO]
  audioresume: exp/${finetune.model}/net_30.pth     # exp/${finetune.model}/net_30.pth (beginning point)
  seconds: [2.0, 2.0]                          # example: [2.0,3.0] variable chunk sampler | [2.0,2.0] fixed 2s
  augmentation: {'speedperturb': [1.0]}
  epochs: 40                                   # num of epochs (train + finetune)
  batchsize: 200                               # batchsize
  optimizer: adam                              # sgd | adam | nadam
  lr_scheduler: steplr                         # steplr | cycliclr 
  warmup_steps: 2000                           # example: 2000 | 0 (no warmup)
  scale: 30                                    # 30 | 32
  margins: [0.2, 0.5]                          # example: [0.0,0.2] gradually increase | [0.2,0.2] fixed margin 0.2
  savemodel_steps: 1                           # save and test performance later
  wandb: off                                   # off | online | offline

test:
  gpus: [0,2]                                  # example: [0] | [3,5] | [] (for cpu)
  audiomodel: MFA-Conformer                         # choose a model from [MODEL ZOO]
  audioresume: exp/co-learning_MFA-Conformer_ResNet18_Fbank80_ASP_emb192_3.0s_steplr/net_8.pth         # exp/${test.model}/net_N.pth (beginning point)
  num_workers_per_gpu: 1                       # example: 1 | 3
  score_norm: asnorm                           # asnorm
  write_score: True

#======================== MODEL Zoo ===========================================================================
# example: MFA-Conformer | ResNet34 | ECAPA-TDNN
ResNet18:
ResNet34:
  feature: Fbank80
ResNet50:
ResNet101:
ResNet152:
ResNet221:
MFA-Conformer:
  feature: Fbank80
  num_blocks: 6
  hidden_dim: 256
  embedding_dim: 192
  input_layer: conv2d2
  pos_enc_layer_type: rel_pos
  pooling: ASP                                # ASP | SP | AP
  loss: AAMSoftmax                            # AAMSoftmax
ECAPA-TDNN:
#========================= Feature ==============================================================================
Fbank80:
  n_mels: 80                                   # num of fbanks
  n_fft: 512                                   # num of fft
  f_min: 20                                    # min frequency
  f_max: 7600                                  # max frequency
  sample_rate: 16000                           # audio sampling rate 
  win_length: 400                              # 25ms (window length)
  hop_length: 160                              # 10ms (window shift)
  window_fn: torch.hamming_window              # window function
#========================== OPTIMIZER ===========================================================================
sgd:
  init_lr: 0.001
  weight_decay: 0.0001
  momentum: 0.9
  nesterov: True
adam:
  init_lr: 0.001
  weight_decay: 0.0000001
#====================== SCORE NORMALIZE =========================================================================
cohort_manifest: data/manifest/cohort_manifest.csv
asnorm:
  submean: True